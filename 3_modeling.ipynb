{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pip installations, libraries, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV, RandomizedSearchCV\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths.\n",
    "DATA_LOC = r'C:\\Users\\enriq\\OneDrive\\Desktop\\Work\\Code\\HitFinder\\Data'\n",
    "TRACKS_LOC = os.path.join(DATA_LOC, 'Tracks')\n",
    "MODELS_LOC = os.path.join(DATA_LOC, 'Models')\n",
    "MODELS_VERSIONED_LOC = os.path.join(MODELS_LOC, 'Versioned')\n",
    "MODELS_FINAL_LOC = os.path.join(MODELS_LOC, 'Final')\n",
    "DATA_PATH = os.path.join(TRACKS_LOC, 'modeling_tracks.csv')\n",
    "FEAT_LISTS_PATH = os.path.join(DATA_LOC, 'Feature Lists', 'feature_lists.p')\n",
    "# Other.\n",
    "NUM_FOLDS = 5\n",
    "NUM_TRAIN_SPLITS = NUM_FOLDS - 1\n",
    "RANDOM_STATE = 0\n",
    "np.random.seed(RANDOM_STATE)\n",
    "DO_LAZYPRED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tracks data.\n",
    "tracks = pd.read_csv(DATA_PATH)\n",
    "tracks = tracks.drop_duplicates(ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in feature lists.\n",
    "with open(FEAT_LISTS_PATH, 'rb') as fp:\n",
    "    feature_lists = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features.\n",
    "TRGT_FEATURE = 'popularity' # or 'is_top_10' for binary classification\n",
    "NON_PREDICTORS = [\n",
    "    'TEST',\n",
    "    'name',\n",
    "    'id',\n",
    "    'artist',\n",
    "    'artist_id',   # keep ?\n",
    "    'album',\n",
    "    'popularity',   # potential target\n",
    "    'is_top_10' # potential target\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and holdout.\n",
    "train_idx, val_idx = tracks['TEST'].isin(range(1, NUM_FOLDS)), tracks['TEST'] == NUM_FOLDS\n",
    "tracks_no_holdout = tracks.loc[train_idx]\n",
    "X, y = tracks.drop(columns = NON_PREDICTORS), tracks[TRGT_FEATURE]\n",
    "X_cv, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "y_cv, y_val = y.loc[train_idx], y.loc[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_lazypred(\n",
    "        feature_list_num: int,\n",
    "        flists: int,\n",
    "        X_train_test: pd.DataFrame = X_cv,\n",
    "        y_train_test: pd.Series = y_cv,\n",
    "        n_models: int = 10,\n",
    "        random_state: int = RANDOM_STATE,\n",
    "):\n",
    "    \n",
    "    # Initialize empty dataframe to hold LazyPredict results.\n",
    "    cols = ['feat_list', 'model', 'test_num', 'test_RMSE']\n",
    "    nan_arr = np.full((NUM_TRAIN_SPLITS * n_models, NUM_TRAIN_SPLITS), np.nan)\n",
    "    metrics = pd.DataFrame(nan_arr, columns = cols)\n",
    "\n",
    "    # Get test metrics for each CV fold.\n",
    "    print('\\nLazyPredict on feature_list_num', feature_list_num)\n",
    "    X_in = X_train_test[flists[feature_list_num]]\n",
    "    for fold_n in range(1, NUM_FOLDS):\n",
    "        test_idx = tracks_no_holdout['TEST'] == fold_n\n",
    "        X_train, X_test = X_in.loc[~test_idx], X_in.loc[test_idx]\n",
    "        y_train, y_test = y_train_test.loc[~test_idx], y_train_test.loc[test_idx]\n",
    "        model = LazyRegressor(random_state = random_state)\n",
    "        print('\\tTesting on fold #', fold_n)\n",
    "        models, _ = model.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Record metrics.\n",
    "        metric_idx = range(fold_n * n_models - n_models, fold_n * n_models)\n",
    "        metrics.loc[metric_idx, 'model'] = models.index.tolist()[:n_models]\n",
    "        metrics.loc[metric_idx, 'test_num'] = fold_n\n",
    "        metrics.loc[metric_idx, 'test_RMSE'] = models[:n_models]['RMSE'].values\n",
    "    metrics['feat_list'] = feature_list_num\n",
    "\n",
    "    # Prepare for output.\n",
    "    print('Doing metrics preparation.')\n",
    "    model_counts = metrics['model'].value_counts()\n",
    "    save_models = model_counts[model_counts >= 3].index.tolist()\n",
    "    save_models_idx = metrics['model'].isin(save_models)\n",
    "    metrics = metrics.loc[save_models_idx]\n",
    "    metrics = metrics.groupby('model').mean() # get RMSE means\n",
    "    metrics = metrics.sort_values('test_RMSE').reset_index()\n",
    "    metrics = metrics.drop(columns = ['test_num'])\n",
    "    metrics = metrics.rename({'test_RMSE': 'avg_test_RMSE'}, axis = 1)\n",
    "    metrics = metrics[['feat_list', 'model', 'avg_test_RMSE']]\n",
    "    metrics['feat_list'] = metrics['feat_list'].astype('int32')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_list</th>\n",
       "      <th>model</th>\n",
       "      <th>avg_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>18.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>18.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>18.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>18.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8</td>\n",
       "      <td>NuSVR</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_list                          model  avg_test_RMSE\n",
       "45          8          RandomForestRegressor          18.57\n",
       "46          8                  LGBMRegressor          18.58\n",
       "47          8  HistGradientBoostingRegressor          18.60\n",
       "38          7                  LGBMRegressor          18.62\n",
       "39          7  HistGradientBoostingRegressor          18.65\n",
       "48          8      GradientBoostingRegressor          18.66\n",
       "31          6                  LGBMRegressor          18.68\n",
       "32          6  HistGradientBoostingRegressor          18.68\n",
       "49          8                   MLPRegressor          18.68\n",
       "50          8                          NuSVR          18.68"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best models for the feature lists obtained.\n",
    "if DO_LAZYPRED:\n",
    "    lazypred_res = pd.DataFrame()\n",
    "    for flist_num in feature_lists:\n",
    "        lazypred_res_tmp = do_lazypred(flist_num, feature_lists)\n",
    "        lazypred_res = pd.concat([lazypred_res, lazypred_res_tmp], ignore_index = True)\n",
    "    # Save LazyPredict results.\n",
    "    lazypred_res.to_csv(os.path.join(DATA_LOC, r'Model Results\\lazypred_res.csv'), index = False)\n",
    "else:\n",
    "    lazypred_res = pd.read_csv(os.path.join(DATA_LOC, r'Model Results\\lazypred_res.csv'))\n",
    "\n",
    "lazypred_res.sort_values('avg_test_RMSE').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Use LazyPredict results to dig further into the indicated models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation splits.\n",
    "cv_no_holdout = PredefinedSplit(tracks_no_holdout['TEST'])  # only 1-4\n",
    "# Define scorer for modeling.\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_model(\n",
    "        model_name: str,\n",
    "        model_lib_str: str,\n",
    "        params: dict,\n",
    "        X_in: pd.DataFrame,\n",
    "        y_in: pd.Series = y_cv,\n",
    "):\n",
    "\n",
    "    # Run the model if it doesn't exist already.\n",
    "    model_path = os.path.join(MODELS_VERSIONED_LOC, model_name)\n",
    "    if model_name not in os.listdir(MODELS_VERSIONED_LOC):\n",
    "        print('Creating', model_name + '.')\n",
    "        estimator = eval(model_lib_str + '(random_state = RANDOM_STATE)')\n",
    "        model = GridSearchCV(\n",
    "            estimator, params, cv = cv_no_holdout, scoring = rmse_scorer,\n",
    "        )\n",
    "        model.fit(X_in, y_in)\n",
    "\n",
    "        # Save model.\n",
    "        with open(model_path, 'wb') as handle:\n",
    "            pickle.dump(model, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    # Read the model in if we already made it.\n",
    "    else:\n",
    "        print('Reading in', model_name + '.')\n",
    "        with open(model_path, 'rb') as handle:\n",
    "            model = pickle.load(handle)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(\n",
    "        model,\n",
    "        X_val_in: pd.DataFrame,\n",
    "        y_val_in: pd.Series = y_val,\n",
    "):\n",
    "\n",
    "    # Get test metrics from the model's best estimator.\n",
    "    best_idx = model.best_index_\n",
    "    res = model.cv_results_\n",
    "    metrics = {\n",
    "        'test_mean_RMSE': float(-res['mean_test_score'][best_idx]),\n",
    "        'test_fold_1_RMSE': float(-res['split0_test_score'][best_idx]),\n",
    "        'test_fold_2_RMSE': float(-res['split1_test_score'][best_idx]),\n",
    "        'test_fold_3_RMSE': float(-res['split2_test_score'][best_idx]),\n",
    "        'test_fold_4_RMSE': float(-res['split3_test_score'][best_idx]),\n",
    "    }\n",
    "\n",
    "    # Get validation metrics.\n",
    "    best_model = model.best_estimator_\n",
    "    val_pred = best_model.predict(X_val_in)\n",
    "    metrics['val_RMSE'] = float(rmse(y_val_in, val_pred))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feat_list_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor (M45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set modeling data.\n",
    "features = feature_lists[8]\n",
    "X_in = X_cv[features].copy()\n",
    "X_val_tmp = X_val[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set modeling parameters.\n",
    "params = {\n",
    "    'criterion': ['squared_error', 'absolute_error'],\n",
    "    'max_depth': [None, 2, 3, 5],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    # 'min_weight_fraction_leaf': [0.0],\n",
    "    # 'max_features': [1.0],\n",
    "    # 'max_leaf_nodes': [None],\n",
    "    # 'min_impurity_decrease': [0.0],\n",
    "    # 'bootstrap': [True],\n",
    "    # 'oob_score': [False],\n",
    "    'n_jobs': [-1],\n",
    "    # 'random_state': [RANDOM_STATE],\n",
    "    # 'verbose': [0],\n",
    "    'warm_start': [False, True],\n",
    "    # 'ccp_alpha': [0.0],\n",
    "    'max_samples': [None],\n",
    "    # 'monotonic_cst': [None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = do_model('m45_v1.pkl', 'RandomForestRegressor', params, X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.best_estimator_.predict(X_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor (M46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set modeling parameters.\n",
    "params = {\n",
    "    # 'boosting_type': ['gbdt'],\n",
    "    'num_leaves': [26, 31, 36],\n",
    "    'max_depth': [-1],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 150],\n",
    "    # 'subsample_for_bin': [200000],\n",
    "    # 'objective': [None],\n",
    "    # 'class_weight': [None],\n",
    "    'min_split_gain': [0.0],\n",
    "    'min_child_weight': [0.01, 0.001, 0.0001],\n",
    "    'min_child_samples': [15, 20],\n",
    "    # 'subsample': [1.0],\n",
    "    # 'subsample_freq': [0],\n",
    "    # 'colsample_bytree': [1.0],\n",
    "    'reg_alpha': [0.0, 0.5],\n",
    "    'reg_lambda': [0.0, 0.5],\n",
    "    # 'random_state': [None],\n",
    "    'n_jobs': [-1],\n",
    "    'importance_type': ['split'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in m46_v1.pkl.\n"
     ]
    }
   ],
   "source": [
    "model = do_model('m46_v1.pkl', 'lgb.LGBMRegressor', params, X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_mean_RMSE': 18.56527882153417,\n",
       " 'test_fold_1_RMSE': 18.664613060420848,\n",
       " 'test_fold_2_RMSE': 18.508549385183954,\n",
       " 'test_fold_3_RMSE': 18.376529221277455,\n",
       " 'test_fold_4_RMSE': 18.711423619254436,\n",
       " 'val_RMSE': 18.682831472086587}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(model, X_val_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingRegressor (M47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor (M48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feat_list_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor (M38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingRegressor (M39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
