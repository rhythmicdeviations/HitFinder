{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_analysis(track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import base64\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from dotenv import load_dotenv\n",
    "from requests import post, get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static variables.\n",
    "# Path names.\n",
    "DATA_LOC = r'C:\\Users\\enriq\\OneDrive\\Desktop\\Work\\Code\\HitFinder\\Data'\n",
    "TRACKS_LOC = os.path.join(DATA_LOC, 'Tracks')\n",
    "# Other.\n",
    "MAX_TRACKS_PER_FN_CALL = 100\n",
    "MY_USERNAME = 'rc3email'   # my profile\n",
    "MY_PLAYLIST_ID = '0a9qA4m3BDqwafHpXxX1zh'\n",
    "TOP_10_STR = 'is_top_10'\n",
    "DO_EXPORT = False\n",
    "RANDOM_STATE = 0\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment first.\n",
    "load_dotenv()\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET')\n",
    "# print(CLIENT_ID, CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spotipy variable.\n",
    "if 'sp_global' not in globals():\n",
    "    sp_global = spotipy.Spotify(\n",
    "        auth_manager = SpotifyOAuth(\n",
    "            client_id = CLIENT_ID,\n",
    "            client_secret = CLIENT_SECRET,\n",
    "            redirect_uri = 'http://localhost:8080',\n",
    "            scope = 'user-library-read',\n",
    "        )\n",
    "    )\n",
    "# This may ask you to copy a link that it takes you to, and paste it into the input box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `spotipy`-based functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_features(\n",
    "        input_dict: dict,\n",
    "        use_tracks_dict: bool,\n",
    "        call_num: int = -1,\n",
    "        sp: spotipy.client.Spotify = sp_global,\n",
    "        max_tracks_per_fn_call: int = MAX_TRACKS_PER_FN_CALL,\n",
    "        top_10_str: str = TOP_10_STR,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get JSON of tracks in a playlist.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    playlist_dict : dict\n",
    "        Playlist to get track data from.\n",
    "    call_num : int\n",
    "        Which call number we are on for the function.\n",
    "        Determines offset to get tracks in playlists with over 100 tracks.\n",
    "    sp : spotipy.client.Spotify\n",
    "        spotipy object to retrieve track data.\n",
    "    max_tracks_per_fn_call : int, default=MAX_TRACKS_PER_FN_CALL\n",
    "        Maximum number of tracks retrieved by certain spotipy functions.\n",
    "    top_10_str : str, default=TOP_10_STR\n",
    "        Name of feature for whether the song is in the artist's top 10.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    tracks : pandas.core.frame.DataFrame\n",
    "        Partial track information without most audio-related features.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the current portion of track names and IDs from the playlist.\n",
    "    offset = call_num * max_tracks_per_fn_call  # use offset to skip ahead in the playlist\n",
    "    # Use playlist to get tracks dictionary if none passed.\n",
    "    if not use_tracks_dict:\n",
    "        tracks_dict = sp.playlist_tracks(input_dict['id'], offset = offset)\n",
    "        tracks_list = [item['track'] for item in tracks_dict['items']]  # subset to track data\n",
    "    else:\n",
    "        tracks_dict = input_dict\n",
    "        track_IDs = [t['id'] for t in tracks_dict['items']]\n",
    "        tracks_list = [sp.track(track_ID) for track_ID in track_IDs]\n",
    "    tracks_list = [t for t in tracks_list if t != None] # remove tracks with no data\n",
    "\n",
    "    # Get specified features from the track that are unavailable later.\n",
    "    feats = ['name', 'id', 'popularity', 'explicit']\n",
    "    tracks = pd.DataFrame([[t[f] for f in feats] for t in tracks_list])\n",
    "    # 'artist' and 'album' are deeper in the dictionary.\n",
    "    deep_feats = ['artist', 'artist_id', 'album']\n",
    "    artist = [(i['artists'][0]['name'], i['artists'][0]['id']) for i in tracks_list]\n",
    "    album = [i['album']['name'] for i in tracks_list]\n",
    "\n",
    "    # Combine data so far.\n",
    "    tracks = pd.concat([tracks, pd.DataFrame(artist), pd.DataFrame(album)], axis = 1)\n",
    "    tracks.columns = feats + deep_feats\n",
    "\n",
    "    # Add top-10 status.\n",
    "    artist_IDs = tracks['artist_id'].unique()\n",
    "    top_tracks = [sp.artist_top_tracks(_ID)['tracks'] for _ID in artist_IDs]\n",
    "    top_tracks_IDs = [item['id'] for sublist in top_tracks for item in sublist]\n",
    "    tracks[top_10_str] = [1 if ID in top_tracks_IDs else 0 for ID in tracks['id']]\n",
    "\n",
    "    # Reorder columns.\n",
    "    new_order = feats[:2] + deep_feats + [feats[2], top_10_str, feats[3]]\n",
    "    tracks = tracks[new_order]\n",
    "    \n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(\n",
    "        tracks: pd.DataFrame,\n",
    "        call_num: int,\n",
    "        sp: spotipy.client.Spotify = sp_global,\n",
    "        max_tracks_per_fn_call: int = MAX_TRACKS_PER_FN_CALL,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get audio features for a set of tracks in a playlist.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    tracks : pandas.core.frame.DataFrame\n",
    "        Tracks data.\n",
    "    call_num : int\n",
    "        Which call number we are on for the function.\n",
    "        Determines indices of the tracks we want to get features for.\n",
    "    sp : spotipy.client.Spotify\n",
    "        spotipy object to retrieve track data.\n",
    "    max_tracks_per_fn_call : int, default=MAX_TRACKS_PER_FN_CALL\n",
    "        Maximum number of tracks retrieved by certain spotipy functions.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    audio_features : pandas.core.frame.DataFrame\n",
    "        Audio features of the tracks we searched for.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get indices of tracks for this call.\n",
    "    lower_idx = call_num * max_tracks_per_fn_call\n",
    "    upper_idx = lower_idx + max_tracks_per_fn_call\n",
    "    # Get audio features for this set of tracks.\n",
    "    tracks_this_call = tracks[lower_idx:upper_idx]\n",
    "    audio_feat_tmp = sp.audio_features(tracks_this_call['id'])\n",
    "    # Remove tracks with no data.\n",
    "    audio_feat_tmp = [f for f in audio_feat_tmp if f != None]\n",
    "    # Convert to dataframe type.\n",
    "    audio_features = pd.DataFrame(audio_feat_tmp)\n",
    "\n",
    "    return audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks_data(\n",
    "        input_dict: dict = {},\n",
    "        max_tracks_per_fn_call: int = MAX_TRACKS_PER_FN_CALL,\n",
    "        tracks_obtained: pd.DataFrame = pd.DataFrame(),\n",
    "):\n",
    "    \"\"\"\n",
    "    Get track data of all tracks in a playlist.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    input_dict : dict\n",
    "        Either the track JSON, or the playlist JSON to get track data from.\n",
    "    max_tracks_per_fn_call : int, default=MAX_TRACKS_PER_FN_CALL\n",
    "        Maximum number of tracks retrieved by certain spotipy functions.\n",
    "    tracks_obtained : pandas.core.frame.DataFrame, default=pd.DataFrame()\n",
    "        Track data we have already obtained so far.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    tracks : pandas.core.frame.DataFrame\n",
    "        Track names, IDs, and audio features.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine dictionary type passed: tracks, or playlist.\n",
    "    use_tracks_dict = False if 'tracks' in input_dict else True\n",
    "    # Initialize beginning track data from tracks in this playlist.\n",
    "    try:\n",
    "        if use_tracks_dict:\n",
    "            num_tracks = input_dict['total']\n",
    "        else:\n",
    "            num_tracks = input_dict['tracks']['total']\n",
    "    except KeyError:\n",
    "        print('Key was not found; max API calls likely exceeded.')\n",
    "        return pd.DataFrame()\n",
    "    # Split the function calls into separate calls if > 100 tracks.\n",
    "    num_fn_calls = math.ceil(num_tracks / max_tracks_per_fn_call)\n",
    "    num_fn_calls_iter = range(num_fn_calls)\n",
    "    tracks = [\n",
    "        get_track_features(input_dict, use_tracks_dict, call_num = n)\n",
    "        for n in num_fn_calls_iter\n",
    "    ]\n",
    "    # Combine data obtained.\n",
    "    tracks = pd.concat([df for df in tracks], ignore_index = True)\n",
    "    # Only get the tracks we need, if we already have some.\n",
    "    if not tracks_obtained.empty:   # check if df has values\n",
    "        tracks = tracks.loc[~tracks['id'].isin(tracks_obtained['id'])]\n",
    "    # Do early stopping if no tracks.\n",
    "    if tracks.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get track audio features in batches of 100.\n",
    "    track_features = [get_audio_features(tracks, n) for n in num_fn_calls_iter]\n",
    "    concat_dt = [df for df in track_features]\n",
    "    track_features = pd.concat(concat_dt, ignore_index = True)\n",
    "\n",
    "    # Merge audio feature data to initial track data.\n",
    "    tracks = pd.merge(left = tracks, right = track_features, how = 'left', on = ['id'])\n",
    "    tracks = tracks.drop(columns = ['type', 'uri', 'track_href', 'analysis_url'])\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom API functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(\n",
    "        client_id: str = CLIENT_ID,\n",
    "        client_secret: str = CLIENT_SECRET,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get token to access Spotify API.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    client_id : str, default=CLIENT_ID\n",
    "        Personal Spotify client ID.\n",
    "    client_secret : str, default=CLIENT_SECRET\n",
    "        Personal Spotify client secret.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    token : str\n",
    "        Token that can be used to access Spotify API.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Get authorization token to access Spotify API.\n",
    "    auth_string = client_id + ':' + client_secret\n",
    "    auth_bytes = auth_string.encode('utf-8')\n",
    "    auth_base64 = str(base64.b64encode(auth_bytes), 'utf-8')\n",
    "    url = 'https://accounts.spotify.com/api/token'\n",
    "    headers = {\n",
    "        'Authorization': 'Basic ' + auth_base64,\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "    data = {'grant_type': 'client_credentials'}\n",
    "    result = post(url, headers = headers, data = data)\n",
    "    json_result = result.json()\n",
    "    token = json_result['access_token']\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth_header(\n",
    "        token: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get authorization header used to bear token to use API.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    token : str\n",
    "        Token that can be used to access Spotify API.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    authorization_header : dict[str]\n",
    "        Authorization header used to get API result.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    authorization_header = {'Authorization': 'Bearer ' + token}\n",
    "\n",
    "    return authorization_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_artist(\n",
    "        token: str,\n",
    "        artist_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Search for an artist by their name using API.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    token : str\n",
    "        Token that can be used to access Spotify API.\n",
    "    artist_name: str\n",
    "        Artist name to search for.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    json_result : dict\n",
    "        JSON of artist information from the search results.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Query artist name.\n",
    "    url = 'https://api.spotify.com/v1/search'\n",
    "    headers = get_auth_header(token)\n",
    "    query = f'?q={artist_name}&type=artist&limit=1'\n",
    "    query_url = url + query\n",
    "    result = get(query_url, headers = headers)\n",
    "    json_result = result.json()['artists']['items']\n",
    "    if len(json_result) == 0:\n",
    "        print('No artist with this name exists.')\n",
    "        return None\n",
    "    json_result = json_result[0]    # get first search result\n",
    "\n",
    "    return json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_tracks(\n",
    "        token: str,\n",
    "        album_ID: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Get track information from a given album.\n",
    "\n",
    "    Parameters\n",
    "    --------\n",
    "    token : str\n",
    "        Token that can be used to access Spotify API.\n",
    "    album_ID: str\n",
    "        Album ID to search for to get track(s) JSON.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    json_result : dict\n",
    "        JSON of album track info from the search results.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Get an artist's top 10 tracks using artist ID.\n",
    "    url = f'https://api.spotify.com/v1/albums/{album_ID}/tracks'\n",
    "    headers = get_auth_header(token)\n",
    "    result = get(url, headers = headers)\n",
    "    try:\n",
    "        json_result = result.json()#['tracks']\n",
    "    # If error, explain potential reason.\n",
    "    except:\n",
    "        if result.status_code == 429:\n",
    "            retry_after = int(result.headers.get('Retry-After', 1))\n",
    "            time_in_min = round(retry_after / 60)\n",
    "            time_in_hrs = round(retry_after / (60 ** 2), 1)\n",
    "            datetime_out = datetime.now() + timedelta(hours = time_in_hrs)\n",
    "            print(\n",
    "                'Rate limited. Timed out for', time_in_min, 'min (' +\n",
    "                str(time_in_hrs), 'hrs). Retry at:', datetime_out\n",
    "            )\n",
    "        json_result = {}\n",
    "\n",
    "    return json_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = get_token()\n",
    "# print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get track data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global top artists tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Listeners</th>\n",
       "      <th>Daily Trend</th>\n",
       "      <th>Peak</th>\n",
       "      <th>PkListeners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>105,759,656</td>\n",
       "      <td>6,626,996</td>\n",
       "      <td>1</td>\n",
       "      <td>105,759,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>105,046,690</td>\n",
       "      <td>6,464,509</td>\n",
       "      <td>1</td>\n",
       "      <td>117,203,987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>95,647,057</td>\n",
       "      <td>4,983,541</td>\n",
       "      <td>1</td>\n",
       "      <td>116,229,071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>87,339,317</td>\n",
       "      <td>7,695,998</td>\n",
       "      <td>4</td>\n",
       "      <td>87,403,624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Post Malone</td>\n",
       "      <td>84,787,711</td>\n",
       "      <td>5,067,028</td>\n",
       "      <td>3</td>\n",
       "      <td>98,466,468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist    Listeners Daily Trend  Peak  PkListeners\n",
       "0  Billie Eilish  105,759,656   6,626,996     1  105,759,656\n",
       "1     The Weeknd  105,046,690   6,464,509     1  117,203,987\n",
       "2   Taylor Swift   95,647,057   4,983,541     1  116,229,071\n",
       "3       Coldplay   87,339,317   7,695,998     4   87,403,624\n",
       "4    Post Malone   84,787,711   5,067,028     3   98,466,468"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read global top artists' names in.\n",
    "# Data source: https://kworb.net/spotify/listeners.html\n",
    "artist_names_path = os.path.join(DATA_LOC, r'tmp\\global_top_artists_names.csv')\n",
    "artist_names = pd.read_csv(artist_names_path)\n",
    "artist_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in previous data at C:\\Users\\enriq\\OneDrive\\Desktop\\Work\\Code\\HitFinder\\Data\\tmp\\global_top_artists_names_IDs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>6qqNVTkY8uBg9cP3Jd7DAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>1Xyo4u8uXC1ZmMpatF05PJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>06HL4z0CvFAxyc27GXpf02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>4gzpq5DPGxSnKTe4SA8HAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Post Malone</td>\n",
       "      <td>246dkjvS1zLTtiykXe5h60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     artist_name               artist_ID\n",
       "0  Billie Eilish  6qqNVTkY8uBg9cP3Jd7DAH\n",
       "1     The Weeknd  1Xyo4u8uXC1ZmMpatF05PJ\n",
       "2   Taylor Swift  06HL4z0CvFAxyc27GXpf02\n",
       "3       Coldplay  4gzpq5DPGxSnKTe4SA8HAU\n",
       "4    Post Malone  246dkjvS1zLTtiykXe5h60"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get artist IDs for the artists in this file.\n",
    "artist_names_IDs_path = os.path.join(DATA_LOC, r'tmp\\global_top_artists_names_IDs.csv')\n",
    "# Use custom function if we don't have the data already.\n",
    "if not os.path.exists(artist_names_IDs_path):\n",
    "    print('Using custom functions to get data.')\n",
    "    artist_names_list = artist_names['Artist'].tolist()\n",
    "    artist_IDs = [search_for_artist(token, name)['id'] for name in artist_names_list]\n",
    "    artist_names_IDs = pd.concat([artist_names['Artist'], pd.Series(artist_IDs)], axis = 1)\n",
    "    artist_names_IDs.columns = ['artist_name', 'artist_ID']\n",
    "    # Export.\n",
    "    artist_names_IDs.to_csv(artist_names_IDs_path, index = False)\n",
    "# Read in the data otherwise.\n",
    "else:\n",
    "    print('Reading in previous data at', artist_names_IDs_path)\n",
    "    artist_names_IDs = pd.read_csv(artist_names_IDs_path)\n",
    "\n",
    "artist_names_IDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in previous data at C:\\Users\\enriq\\OneDrive\\Desktop\\Work\\Code\\HitFinder\\Data\\tmp\\global_top_artists_album_IDs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7aJuG4TFXa2hmE4z1yxc3n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0JGOiO34nwfUdDrD612dOp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0S0KGZnfBGSIssfF54WSJh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ThlxfLSy4bfKzxWqmC7VN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4YCeHlXgJTKlzuwHmvZZo8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 album_ID\n",
       "0  7aJuG4TFXa2hmE4z1yxc3n\n",
       "1  0JGOiO34nwfUdDrD612dOp\n",
       "2  0S0KGZnfBGSIssfF54WSJh\n",
       "3  3ThlxfLSy4bfKzxWqmC7VN\n",
       "4  4YCeHlXgJTKlzuwHmvZZo8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get artist's album IDs.\n",
    "album_IDs_path = os.path.join(DATA_LOC, r'tmp\\global_top_artists_album_IDs.csv')\n",
    "# Use spotipy to get data if we don't have the data already.\n",
    "if not os.path.exists(artist_names_IDs_path):\n",
    "    print('Using spotipy to get data.')\n",
    "    artist_IDs = artist_names_IDs['artist_ID'].tolist()\n",
    "    album_IDs = [\n",
    "        [\n",
    "            album['id']\n",
    "            for album in sp_global.artist_albums(_ID)['items']\n",
    "        ]\n",
    "        for _ID in artist_IDs\n",
    "    ]\n",
    "    album_IDs = pd.Series([item for row in album_IDs for item in row])\n",
    "    album_IDs = pd.DataFrame(album_IDs, columns = ['album_ID'])\n",
    "    # Export.\n",
    "    album_IDs.to_csv(album_IDs_path, index = False)\n",
    "# Read in the data otherwise.\n",
    "else:\n",
    "    print('Reading in previous data at', album_IDs_path)\n",
    "    album_IDs = pd.read_csv(album_IDs_path)\n",
    "\n",
    "album_IDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set chunks obtained.\n",
    "fname = 'global_top_artist_tracks_chunk_IDs_obtained.csv'\n",
    "chunk_IDs_obtained_path = os.path.join(TRACKS_LOC, fname)\n",
    "if not os.path.exists(chunk_IDs_obtained_path):\n",
    "    chunk_IDs_obtained = pd.DataFrame(columns = ['chunk_ID'])\n",
    "else:\n",
    "    chunk_IDs_obtained = pd.read_csv(chunk_IDs_obtained_path)\n",
    "\n",
    "# Set tracks obtained from these chunks.\n",
    "fname = 'global_top_artist_tracks.csv'\n",
    "all_tracks_obtained_path = os.path.join(TRACKS_LOC, fname)\n",
    "if not os.path.exists(all_tracks_obtained_path):\n",
    "    all_tracks_obtained = pd.DataFrame()\n",
    "else:\n",
    "    all_tracks_obtained = pd.read_csv(all_tracks_obtained_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4qZBW3f2Q8y0k1A84d4iAO',\n",
       " '3lS1y25WAhcqJDATJK70Mq',\n",
       " '2OkEsqGTfu8PWRrNHzfr0m',\n",
       " '3HHNR44YbP7XogMVwzbodx',\n",
       " '1Kw1bVd07oRqcjrcjQKC8T']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are very many albums, so we need to cut the list down and chunk it.\n",
    "# Start at a chunk we don't already have.\n",
    "chunk_ID_start = 0\n",
    "while chunk_ID_start in set(chunk_IDs_obtained['chunk_ID']):\n",
    "    chunk_ID_start += 1\n",
    "# Get every nth album.\n",
    "n_step = 20\n",
    "album_IDs_subset = album_IDs.iloc[chunk_ID_start::n_step]\n",
    "album_IDs_list = [album_ID for album_ID in album_IDs_subset['album_ID']]\n",
    "# Get chunks of albums for separate function calls.\n",
    "chunk_size = 50\n",
    "album_IDs_chunks = [\n",
    "    album_IDs_list[i:i + chunk_size]\n",
    "    for i in range(0, len(album_IDs_list), chunk_size)\n",
    "]\n",
    "album_IDs_chunks[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for global_top_artist_tracks_chunk_26.csv...\n",
      "File not found. Getting data from Spotify.\n"
     ]
    }
   ],
   "source": [
    "# Get tracks from albums specified.\n",
    "chunk_added = False\n",
    "for idx, album_ID_chunk in enumerate(album_IDs_chunks):\n",
    "\n",
    "    # Set file name using chunk we're currently on.\n",
    "    chunk_ID = (idx * n_step) + chunk_ID_start\n",
    "    fname = 'global_top_artist_tracks_chunk_' + str(chunk_ID) + '.csv'\n",
    "    global_top_artist_tracks_path = os.path.join(TRACKS_LOC, fname)\n",
    "\n",
    "    # Use spotipy to get data if we don't have the data already.\n",
    "    global_top_artist_tracks = pd.DataFrame()\n",
    "    if chunk_ID not in chunk_IDs_obtained.values:\n",
    "        print('Checking for', fname + '...\\nFile not found. Getting data from Spotify.')\n",
    "        if chunk_added:\n",
    "            time.sleep(0)  # space out calls\n",
    "        for album_ID in album_ID_chunk:\n",
    "            tracks_dict = get_album_tracks(token, album_ID)\n",
    "            new_tracks = get_tracks_data(tracks_dict, tracks_obtained = global_top_artist_tracks)\n",
    "            concat_dt = [global_top_artist_tracks, new_tracks]\n",
    "            global_top_artist_tracks = pd.concat(concat_dt, ignore_index = True)\n",
    "        # Export if data was returned.\n",
    "        if global_top_artist_tracks.empty:\n",
    "            break\n",
    "        print('Exporting chunk ID', chunk_ID, 'to', global_top_artist_tracks_path)\n",
    "        global_top_artist_tracks.to_csv(global_top_artist_tracks_path, index = False)\n",
    "\n",
    "        # Update chunk IDs obtained.\n",
    "        chunk_IDs_obtained.loc[len(chunk_IDs_obtained), 'chunk_ID'] = chunk_ID\n",
    "        chunk_IDs_obtained = chunk_IDs_obtained.sort_values('chunk_ID').astype('int32')\n",
    "        chunk_IDs_obtained.to_csv(chunk_IDs_obtained_path, index = False)\n",
    "        chunk_added = True\n",
    "    else:\n",
    "        print('Checking for', fname + '...\\nFile found.')\n",
    "\n",
    "# global_top_artist_tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update chunks/tracks obtained.\n",
    "tracks_fnames = os.listdir(TRACKS_LOC)\n",
    "chunk_files = [f for f in tracks_fnames if '_chunk_' in f and 'IDs_obtained' not in f]\n",
    "\n",
    "if chunk_files != []:\n",
    "    # Combine chunked track output dataframes.\n",
    "    chunk_paths = [os.path.join(TRACKS_LOC, f) for f in chunk_files]\n",
    "    new_data = pd.concat([pd.read_csv(p) for p in chunk_paths], ignore_index = True)\n",
    "    all_tracks_obtained = pd.concat([all_tracks_obtained, new_data], ignore_index = True)\n",
    "    all_tracks_obtained.to_csv(all_tracks_obtained_path, index = False)\n",
    "\n",
    "    # Move old chunked files.\n",
    "    chunk_paths_new = [os.path.join(TRACKS_LOC, 'old', f) for f in chunk_files]\n",
    "    for old_path, new_path in list(zip(chunk_paths, chunk_paths_new)):\n",
    "        try:\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"File '{old_path}' moved to '{new_path}'.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File '{old_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one of my playlists :-).\n",
    "my_playlist_path = os.path.join(TRACKS_LOC, 'my_playlist_tracks.csv')\n",
    "# Use spotipy to get data if we don't have the data already.\n",
    "if not os.path.exists(my_playlist_path):\n",
    "    print('Using spotipy to get track data.')\n",
    "    playlists = sp_global.user_playlists(MY_USERNAME)\n",
    "    my_playlist_tracks = pd.DataFrame()\n",
    "    playlist = [p for p in playlists['items'] if p['id'] == MY_PLAYLIST_ID][0]\n",
    "    print(f'Playlist:', playlist['name'], '\\nID:', playlist['id'])\n",
    "    my_playlist_tracks = get_tracks_data(playlist)\n",
    "    # Export.\n",
    "    my_playlist_tracks.to_csv(my_playlist_path, index = False)\n",
    "# Read in the data otherwise.\n",
    "else:\n",
    "    print('Reading in previous data at', my_playlist_path)\n",
    "    my_playlist_tracks = pd.read_csv(my_playlist_path)\n",
    "\n",
    "# my_playlist_tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get many playlists for larger data pool.\n",
    "spotify_sample_tracks_path = os.path.join(TRACKS_LOC, 'spotify_sample_tracks.csv')\n",
    "# Use spotipy to get data if we don't have the data already.\n",
    "if not os.path.exists(spotify_sample_tracks_path):\n",
    "    print('Using spotipy to get track data.')\n",
    "    playlists = sp_global.user_playlists('spotify')\n",
    "    spotify_sample_tracks = pd.DataFrame()\n",
    "    for idx, playlist in enumerate(playlists['items']):\n",
    "        print(f'Playlist #{idx+1}:', playlist['name'])\n",
    "        new_tracks = get_tracks_data(playlist, tracks_obtained = spotify_sample_tracks)\n",
    "        spotify_sample_tracks = pd.concat([spotify_sample_tracks, new_tracks], ignore_index = True)\n",
    "    # Export.\n",
    "    spotify_sample_tracks.to_csv(spotify_sample_tracks_path, index = False)\n",
    "# Read in the data otherwise.\n",
    "else:\n",
    "    print('Reading in previous data at', spotify_sample_tracks_path)\n",
    "    spotify_sample_tracks = pd.read_csv(spotify_sample_tracks_path)\n",
    "\n",
    "# spotify_sample_tracks.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
